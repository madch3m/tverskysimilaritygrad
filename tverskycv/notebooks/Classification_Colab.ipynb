{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fruits-360 Classification with Feature Sharing\n",
    "\n",
    "This notebook demonstrates parameter-efficient fruit classification using **SharedTverskyLinear** layers with the **GlobalFeature bank** for feature sharing. The model uses Tversky similarity-based projections that share feature matrices across layers, significantly reducing the number of trainable parameters.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/YOUR_USERNAME/tverskysimilaritygrad/blob/main/tverskycv/notebooks/Fruits360_FeatureSharing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "Install required packages and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (for Colab users)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Detect if running in Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules or os.path.exists('/content')\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Check if repository is already cloned\n",
    "    repo_path = '/content/tverskysimilaritygrad'\n",
    "    if not os.path.exists(repo_path):\n",
    "        print(\"Cloning repository from GitHub...\")\n",
    "        print(\"Note: Replace YOUR_USERNAME with your actual GitHub username\")\n",
    "        # Uncomment and update the line below with your GitHub username\n",
    "        # !git clone https://github.com/YOUR_USERNAME/tverskysimilaritygrad.git\n",
    "        # Or use the direct repository URL if public\n",
    "        # !git clone https://github.com/YOUR_USERNAME/tverskysimilaritygrad.git /content/tverskysimilaritygrad\n",
    "        print(\"\u26a0 Please uncomment and update the git clone line above with your repository URL\")\n",
    "    else:\n",
    "        print(f\"\u2713 Repository already exists at {repo_path}\")\n",
    "    \n",
    "    # Change to repository directory if it exists\n",
    "    if os.path.exists(repo_path):\n",
    "        os.chdir(repo_path)\n",
    "        print(f\"\u2713 Changed to: {os.getcwd()}\")\n",
    "    else:\n",
    "        print(f\"\u26a0 Repository not found. Please clone it first.\")\n",
    "else:\n",
    "    print(\"\u2713 Running locally - assuming repository is already available\")\n",
    "    print(\"  If you need to clone, run: git clone https://github.com/YOUR_USERNAME/tverskysimilaritygrad.git\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install torch torchvision transformers numpy matplotlib seaborn tqdm datasets Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Setup Path\n",
    "\n",
    "Import necessary modules and set up the project path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "import sys\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Automatic path setup for both Colab and local development\n",
    "_current_dir = os.getcwd()\n",
    "_project_root = None\n",
    "\n",
    "# Try to find project root (directory containing tverskycv folder)\n",
    "_search_paths = [\n",
    "    _current_dir,\n",
    "    os.path.join(_current_dir, '..'),\n",
    "    os.path.join(_current_dir, '..', '..'),\n",
    "    os.path.join(_current_dir, '..', '..', '..'),\n",
    "    '/content/tverskysimilaritygrad',  # Colab default\n",
    "]\n",
    "\n",
    "for path in _search_paths:\n",
    "    abs_path = os.path.abspath(path)\n",
    "    if os.path.exists(os.path.join(abs_path, 'tverskycv')):\n",
    "        _project_root = abs_path\n",
    "        break\n",
    "\n",
    "# Change to project root if found\n",
    "if _project_root:\n",
    "    os.chdir(_project_root)\n",
    "    if _project_root not in sys.path:\n",
    "        sys.path.insert(0, _project_root)\n",
    "    print(f\"\u2713 Project root detected: {_project_root}\")\n",
    "    print(f\"\u2713 Working directory: {os.getcwd()}\")\n",
    "else:\n",
    "    # Fallback: try adding current directory and common paths\n",
    "    _fallback_paths = [\n",
    "        os.path.abspath('.'),\n",
    "        os.path.abspath('..'),\n",
    "        os.path.abspath('../..'),\n",
    "    ]\n",
    "    for path in _fallback_paths:\n",
    "        if path not in sys.path:\n",
    "            sys.path.insert(0, path)\n",
    "    print(\"\u26a0 Could not detect project root. Trying fallback paths.\")\n",
    "\n",
    "# Import Tversky modules\n",
    "try:\n",
    "    from tverskycv.models.backbones.shared_tversky import SharedTverskyLinear, GlobalFeature\n",
    "    print(\"\u2713 Imports successful!\")\n",
    "except ImportError as e:\n",
    "    print(f\"\u274c Import error: {e}\")\n",
    "    print(\"Make sure you've cloned the repository and added it to the Python path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding Feature Sharing\n",
    "\n",
    "**SharedTverskyLinear** uses the **GlobalFeature bank** to share feature matrices and Tversky parameters across multiple layers:\n",
    "\n",
    "- **Feature Matrix Sharing**: Multiple layers share the same feature transformation matrix\n",
    "- **Parameter Reduction**: Significantly fewer trainable parameters compared to standard linear layers\n",
    "- **Tversky Similarity**: Uses psychologically plausible similarity measure instead of dot product\n",
    "\n",
    "### Key Benefits:\n",
    "- **Parameter Efficiency**: Shared features reduce total parameters by 50-90%\n",
    "- **Memory Efficient**: Lower memory footprint during training and inference\n",
    "- **Maintains Performance**: Shared features can still learn effective representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Fruits-360 Dataset\n",
    "\n",
    "Load the fruits-360 dataset from Hugging Face and prepare it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab-specific optimizations\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "# Load fruits-360 dataset from Hugging Face\n",
    "print(\"Loading fruits-360 dataset...\")\n",
    "ds = load_dataset(\"PedroSampaio/fruits-360\")\n",
    "\n",
    "print(f\"\\nDataset splits: {list(ds.keys())}\")\n",
    "print(f\"Train samples: {len(ds['train'])}\")\n",
    "if 'test' in ds:\n",
    "    print(f\"Test samples: {len(ds['test'])}\")\n",
    "if 'validation' in ds:\n",
    "    print(f\"Validation samples: {len(ds['validation'])}\")\n",
    "\n",
    "# Get number of classes\n",
    "if 'train' in ds:\n",
    "    labels = ds['train']['label']\n",
    "    num_classes = len(set(labels))\n",
    "    print(f\"\\nNumber of classes: {num_classes}\")\n",
    "    print(f\"Sample labels: {sorted(set(labels))[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize to 64x64 for faster training\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "])\n",
    "\n",
    "def transform_dataset(examples):\n",
    "    \"\"\"Transform images in the dataset.\"\"\"\n",
    "    images = examples['image']\n",
    "    transformed_images = []\n",
    "    \n",
    "    for img in images:\n",
    "        if isinstance(img, Image.Image):\n",
    "            img_tensor = transform(img)\n",
    "        elif isinstance(img, np.ndarray):\n",
    "            img_pil = Image.fromarray(img)\n",
    "            img_tensor = transform(img_pil)\n",
    "        else:\n",
    "            img_tensor = torch.tensor(img) if not isinstance(img, torch.Tensor) else img\n",
    "        transformed_images.append(img_tensor.numpy())\n",
    "    \n",
    "    examples['image'] = transformed_images\n",
    "    return examples\n",
    "\n",
    "# Apply transformations\n",
    "print(\"Transforming dataset...\")\n",
    "train_data_transformed = ds['train'].map(\n",
    "    transform_dataset, \n",
    "    batched=True, \n",
    "    batch_size=100,\n",
    "    remove_columns=[col for col in ds['train'].column_names if col not in ['image', 'label']]\n",
    ")\n",
    "\n",
    "if 'test' in ds:\n",
    "    test_data_transformed = ds['test'].map(\n",
    "        transform_dataset,\n",
    "        batched=True,\n",
    "        batch_size=100,\n",
    "        remove_columns=[col for col in ds['test'].column_names if col not in ['image', 'label']]\n",
    "    )\n",
    "else:\n",
    "    # Use validation as test if test split doesn't exist\n",
    "    test_data_transformed = ds['validation'].map(\n",
    "        transform_dataset,\n",
    "        batched=True,\n",
    "        batch_size=100,\n",
    "        remove_columns=[col for col in ds['validation'].column_names if col not in ['image', 'label']]\n",
    "    )\n",
    "\n",
    "print(\"\u2713 Dataset transformation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch Dataset wrapper\n",
    "class Fruits360Dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        image = item['image']\n",
    "        label = item['label']\n",
    "        \n",
    "        # Convert to tensor if needed\n",
    "        if not isinstance(image, torch.Tensor):\n",
    "            if isinstance(image, list):\n",
    "                image = torch.tensor(image)\n",
    "            elif isinstance(image, np.ndarray):\n",
    "                image = torch.from_numpy(image)\n",
    "            else:\n",
    "                image = torch.tensor(image)\n",
    "        \n",
    "        # Flatten image for feature sharing model\n",
    "        image_flat = image.flatten()\n",
    "        \n",
    "        return image_flat, label\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Fruits360Dataset(train_data_transformed)\n",
    "test_dataset = Fruits360Dataset(test_data_transformed)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=0,  # Set to 0 for Colab compatibility\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "print(f\"\u2713 Data loaders created!\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Get feature dimension\n",
    "sample_image, _ = train_dataset[0]\n",
    "feature_dim = sample_image.shape[0]\n",
    "print(f\"  Feature dimension: {feature_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Model with Feature Sharing\n",
    "\n",
    "Create a classification model using SharedTverskyLinear layers with feature sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FruitsClassifierWithSharing(nn.Module):\n",
    "    \"\"\"Fruit classifier using SharedTverskyLinear with feature sharing.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dims, num_classes, feature_key='fruits', share_features=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Input layer\n",
    "        dims = [input_dim] + hidden_dims + [num_classes]\n",
    "        \n",
    "        for i in range(len(dims) - 1):\n",
    "            in_dim = dims[i]\n",
    "            out_dim = dims[i + 1]\n",
    "            \n",
    "            # Use SharedTverskyLinear with feature sharing\n",
    "            layer = SharedTverskyLinear(\n",
    "                in_features=in_dim,\n",
    "                out_features=out_dim,\n",
    "                feature_key=feature_key,  # Same key = shared features\n",
    "                alpha=0.5,\n",
    "                beta=0.5,\n",
    "                gamma=1.0,\n",
    "                share_features=share_features\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            x = layer(x)\n",
    "            x = F.relu(x)  # Activation between layers\n",
    "        \n",
    "        # Final layer (no activation)\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "# Model configuration\n",
    "hidden_dims = [512, 256, 128]  # Hidden layer dimensions\n",
    "feature_key = 'fruits_shared'  # Shared feature key\n",
    "\n",
    "# Clear GlobalFeature bank before creating model\n",
    "gf = GlobalFeature()\n",
    "gf.clear()\n",
    "\n",
    "# Create model with feature sharing\n",
    "model_shared = FruitsClassifierWithSharing(\n",
    "    input_dim=feature_dim,\n",
    "    hidden_dims=hidden_dims,\n",
    "    num_classes=num_classes,\n",
    "    feature_key=feature_key,\n",
    "    share_features=True  # Enable feature sharing\n",
    ")\n",
    "\n",
    "print(f\"\u2713 Model with feature sharing created!\")\n",
    "print(f\"  Input dimension: {feature_dim}\")\n",
    "print(f\"  Hidden dimensions: {hidden_dims}\")\n",
    "print(f\"  Number of classes: {num_classes}\")\n",
    "\n",
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "params_shared = count_parameters(model_shared)\n",
    "print(f\"  Total parameters: {params_shared:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Parameter Efficiency Analysis\n",
    "\n",
    "Compare models with and without feature sharing to demonstrate parameter reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model WITHOUT feature sharing for comparison\n",
    "gf.clear()  # Clear before creating non-shared model\n",
    "\n",
    "model_no_sharing = FruitsClassifierWithSharing(\n",
    "    input_dim=feature_dim,\n",
    "    hidden_dims=hidden_dims,\n",
    "    num_classes=num_classes,\n",
    "    feature_key='fruits_no_sharing',\n",
    "    share_features=False  # Disable feature sharing\n",
    ")\n",
    "\n",
    "params_no_sharing = count_parameters(model_no_sharing)\n",
    "\n",
    "# Calculate reduction\n",
    "reduction = ((params_no_sharing - params_shared) / params_no_sharing) * 100\n",
    "params_saved = params_no_sharing - params_shared\n",
    "\n",
    "print(\"Parameter Efficiency Comparison:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Model with feature sharing:    {params_shared:,} parameters\")\n",
    "print(f\"Model without feature sharing: {params_no_sharing:,} parameters\")\n",
    "print(f\"Parameters saved:              {params_saved:,}\")\n",
    "print(f\"Reduction:                      {reduction:.2f}%\")\n",
    "print(f\"Efficiency ratio:               {params_no_sharing / params_shared:.2f}x fewer parameters\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Analyze shared features\n",
    "print(\"\\nShared Feature Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "# Re-create shared model to see features\n",
    "gf.clear()\n",
    "model_shared_check = FruitsClassifierWithSharing(\n",
    "    input_dim=feature_dim,\n",
    "    hidden_dims=hidden_dims,\n",
    "    num_classes=num_classes,\n",
    "    feature_key=feature_key,\n",
    "    share_features=True\n",
    ")\n",
    "shared_features = gf._feature_matrices\n",
    "total_shared_params = 0\n",
    "\n",
    "for key, value in shared_features.items():\n",
    "    if isinstance(value, nn.Parameter):\n",
    "        param_count = value.numel()\n",
    "        total_shared_params += param_count\n",
    "        print(f\"  {key}: {param_count:,} parameters\")\n",
    "    elif isinstance(value, dict):\n",
    "        param_count = sum(p.numel() for p in value.values() if isinstance(p, nn.Parameter))\n",
    "        total_shared_params += param_count\n",
    "        print(f\"  {key}: {param_count:,} parameters (Tversky params)\")\n",
    "\n",
    "print(f\"\\nTotal shared parameters: {total_shared_params:,}\")\n",
    "if params_shared > 0:\n",
    "    print(f\"Shared percentage: {(total_shared_params / params_shared * 100):.2f}%\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Traditional CNN\n",
    "\n",
    "Now let's compare with a traditional convolutional neural network to see the parameter difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional CNN Model for comparison\n",
    "class TraditionalCNN(nn.Module):\n",
    "    \"\"\"Traditional convolutional neural network for fruit classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, img_size=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling layers\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Calculate flattened size after convolutions\n",
    "        # After 3 pooling operations: 64 -> 32 -> 16 -> 8\n",
    "        self.flattened_size = 128 * 8 * 8\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshape flattened input back to image format\n",
    "        # Assuming input is flattened (B, 64*64*3) = (B, 12288)\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, 3, 64, 64)\n",
    "        \n",
    "        # Convolutional layers with pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 64x64 -> 32x32\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 32x32 -> 16x16\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # 16x16 -> 8x8\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(batch_size, -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create traditional CNN model\n",
    "model_cnn = TraditionalCNN(num_classes=num_classes, img_size=64)\n",
    "params_cnn = count_parameters(model_cnn)\n",
    "\n",
    "print(\"Traditional CNN Model:\")\n",
    "print(f\"  Total parameters: {params_cnn:,}\")\n",
    "print(f\"  Architecture: Conv2d layers + MaxPool + Fully Connected layers\")\n",
    "print(f\"  Conv layers: 3x3 convs with 32, 64, 128 channels\")\n",
    "print(f\"  FC layers: 512 -> 256 -> 128 -> {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three-way Parameter Comparison\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE PARAMETER COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n1. Feature Sharing Model (SharedTverskyLinear):\")\n",
    "print(f\"   Parameters: {params_shared:,} ({params_shared/1e6:.2f}M)\")\n",
    "print(f\"   Architecture: SharedTverskyLinear with GlobalFeature bank\")\n",
    "print(f\"   Feature: Parameter sharing across layers\")\n",
    "\n",
    "print(f\"\\n2. No Sharing Model (SharedTverskyLinear, no sharing):\")\n",
    "print(f\"   Parameters: {params_no_sharing:,} ({params_no_sharing/1e6:.2f}M)\")\n",
    "print(f\"   Architecture: SharedTverskyLinear without feature sharing\")\n",
    "print(f\"   Feature: Each layer has its own features\")\n",
    "\n",
    "print(f\"\\n3. Traditional CNN Model:\")\n",
    "print(f\"   Parameters: {params_cnn:,} ({params_cnn/1e6:.2f}M)\")\n",
    "print(f\"   Architecture: Conv2d + MaxPool + Linear layers\")\n",
    "print(f\"   Feature: Standard convolutional neural network\")\n",
    "\n",
    "# Calculate reductions\n",
    "reduction_vs_no_sharing = ((params_no_sharing - params_shared) / params_no_sharing) * 100\n",
    "reduction_vs_cnn = ((params_cnn - params_shared) / params_cnn) * 100\n",
    "reduction_cnn_vs_no_sharing = ((params_no_sharing - params_cnn) / params_no_sharing) * 100\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"PARAMETER REDUCTION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nFeature Sharing vs No Sharing:\")\n",
    "print(f\"  Reduction: {reduction_vs_no_sharing:.2f}%\")\n",
    "print(f\"  Parameters saved: {params_no_sharing - params_shared:,}\")\n",
    "print(f\"  Efficiency: {params_no_sharing / params_shared:.2f}x fewer parameters\")\n",
    "\n",
    "print(f\"\\nFeature Sharing vs Traditional CNN:\")\n",
    "print(f\"  Reduction: {reduction_vs_cnn:.2f}%\")\n",
    "print(f\"  Parameters saved: {params_cnn - params_shared:,}\")\n",
    "print(f\"  Efficiency: {params_cnn / params_shared:.2f}x fewer parameters\")\n",
    "\n",
    "print(f\"\\nTraditional CNN vs No Sharing:\")\n",
    "if params_cnn < params_no_sharing:\n",
    "    print(f\"  CNN has {params_no_sharing - params_cnn:,} fewer parameters ({reduction_cnn_vs_no_sharing:.2f}% reduction)\")\n",
    "else:\n",
    "    print(f\"  No Sharing model has {params_cnn - params_no_sharing:,} fewer parameters\")\n",
    "\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize three-way parameter comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart comparison (all three models)\n",
    "ax1 = axes[0]\n",
    "models = ['Feature\\nSharing', 'No\\nSharing', 'Traditional\\nCNN']\n",
    "params = [params_shared, params_no_sharing, params_cnn]\n",
    "colors = ['#2ecc71', '#e74c3c', '#3498db']\n",
    "\n",
    "bars = ax1.bar(models, params, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax1.set_ylabel('Number of Parameters', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Parameter Count: All Model Types Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add value labels\n",
    "for bar, param in zip(bars, params):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{param:,}\\n({param/1e6:.2f}M)',\n",
    "            ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Reduction percentages comparison\n",
    "ax2 = axes[1]\n",
    "reductions = [reduction_vs_no_sharing, reduction_vs_cnn]\n",
    "reduction_labels = ['vs No Sharing', 'vs Traditional CNN']\n",
    "colors_reduction = ['#e74c3c', '#3498db']\n",
    "\n",
    "bars2 = ax2.bar(reduction_labels, reductions, color=colors_reduction, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax2.set_ylabel('Parameter Reduction (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Feature Sharing: Parameter Reduction', fontsize=14, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add value labels\n",
    "for bar, reduction in zip(bars2, reductions):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{reduction:.2f}%',\n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Model Type':<25} {'Parameters':<20} {'Reduction vs CNN':<20}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Feature Sharing':<25} {params_shared:>18,} ({params_shared/1e6:>5.2f}M) {reduction_vs_cnn:>18.2f}%\")\n",
    "print(f\"{'No Sharing':<25} {params_no_sharing:>18,} ({params_no_sharing/1e6:>5.2f}M) {'N/A':>20}\")\n",
    "print(f\"{'Traditional CNN':<25} {params_cnn:>18,} ({params_cnn/1e6:>5.2f}M) {'Baseline':>20}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Setup\n",
    "\n",
    "Set up training configuration and utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Use the shared model for training\n",
    "gf.clear()\n",
    "model = FruitsClassifierWithSharing(\n",
    "    input_dim=feature_dim,\n",
    "    hidden_dims=hidden_dims,\n",
    "    num_classes=num_classes,\n",
    "    feature_key=feature_key,\n",
    "    share_features=True\n",
    ").to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "print(f\"\\n\u2713 Training setup complete!\")\n",
    "print(f\"  Loss function: CrossEntropyLoss\")\n",
    "print(f\"  Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"  Scheduler: StepLR (step_size=5, gamma=0.5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Loop\n",
    "\n",
    "Train the model with feature sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_epochs = 10\n",
    "\n",
    "# Track metrics\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Starting Training for {num_epochs} epochs\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_train_correct = 0\n",
    "    epoch_train_total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        epoch_train_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        epoch_train_correct += (preds == labels).sum().item()\n",
    "        epoch_train_total += labels.size(0)\n",
    "        \n",
    "        # Print progress\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            current_loss = epoch_train_loss / (batch_idx + 1)\n",
    "            current_acc = epoch_train_correct / epoch_train_total\n",
    "            print(f\"  Batch {batch_idx+1}/{len(train_loader)}: Loss={current_loss:.4f}, Acc={current_acc:.4f}\")\n",
    "    \n",
    "    # Calculate average training metrics\n",
    "    train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_acc = epoch_train_correct / epoch_train_total\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0.0\n",
    "    epoch_val_correct = 0\n",
    "    epoch_val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            epoch_val_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            epoch_val_correct += (preds == labels).sum().item()\n",
    "            epoch_val_total += labels.size(0)\n",
    "    \n",
    "    # Calculate average validation metrics\n",
    "    val_loss = epoch_val_loss / len(test_loader)\n",
    "    val_acc = epoch_val_correct / epoch_val_total\n",
    "    \n",
    "    # Store metrics\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Train - Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"  Val   - Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"  Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    print(f\"  {'-'*60}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Training Complete!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Final Training Accuracy: {train_accuracies[-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {val_accuracies[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Training Results\n",
    "\n",
    "Plot training curves and analyze model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(train_losses, label='Train Loss', marker='o', linewidth=2)\n",
    "axes[0].plot(val_losses, label='Val Loss', marker='s', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(train_accuracies, label='Train Acc', marker='o', linewidth=2)\n",
    "axes[1].plot(val_accuracies, label='Val Acc', marker='s', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Evaluation\n",
    "\n",
    "Evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test evaluation\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "print(\"Evaluating on test set...\")\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        test_correct += (preds == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss = test_loss / len(test_loader)\n",
    "test_acc = test_correct / test_total\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Final Test Results\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f} ({test_correct}/{test_total})\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Per-class accuracy (top 10)\n",
    "correct_by_class = Counter()\n",
    "total_by_class = Counter()\n",
    "\n",
    "for pred, label in zip(all_preds, all_labels):\n",
    "    total_by_class[label] += 1\n",
    "    if pred == label:\n",
    "        correct_by_class[label] += 1\n",
    "\n",
    "print(f\"\\nPer-class accuracy (top 10 classes):\")\n",
    "class_accuracies = {cls: correct_by_class[cls] / total_by_class[cls] \n",
    "                    for cls in sorted(total_by_class.keys())[:10]}\n",
    "for cls, acc in sorted(class_accuracies.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  Class {cls}: {acc:.4f} ({correct_by_class[cls]}/{total_by_class[cls]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Parameter Efficiency**: Feature sharing significantly reduces the number of trainable parameters\n",
    "2. **Performance**: The model maintains good classification performance despite fewer parameters\n",
    "3. **Memory Efficiency**: Lower memory footprint enables training on resource-constrained devices\n",
    "4. **Scalability**: Parameter reduction becomes more significant with larger models\n",
    "\n",
    "### Feature Sharing Benefits:\n",
    "\n",
    "- **Shared Feature Matrices**: Multiple layers share the same feature transformation\n",
    "- **Shared Tversky Parameters**: Alpha, beta, and gamma parameters are shared across layers\n",
    "- **GlobalFeature Bank**: Centralized parameter storage for efficient sharing\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Experiment with different feature_key values for different sharing strategies\n",
    "- Try different hidden layer dimensions\n",
    "- Compare with standard linear layers\n",
    "- Fine-tune Tversky parameters (alpha, beta, gamma) for better performance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}